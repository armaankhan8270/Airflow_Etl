ğŸ“° News ETL Pipeline using Apache Airflow & PostgreSQL

A production-grade, fully local ETL pipeline that extracts real-time tech news from NewsAPI, transforms the data, and loads it into a PostgreSQL database â€” all orchestrated using Apache Airflow.

> âŒ No cloud tools. âœ… 100% Open Source. ğŸ³ Dockerized. ğŸ› ï¸ Real-world setup.

---

 ğŸ“Œ Features

- â° **Daily ETL Scheduling** with Apache Airflow
- ğŸ§ª **Data Cleaning & Normalization** during transformation
- ğŸ—ƒï¸ **Structured Storage** into PostgreSQL
- ğŸ” **Retry logic & Logging** with Airflow DAGs
- ğŸ“¦ **Dockerized** for easy setup and consistent environments

---

 ğŸ§± Project Structure


```markdown

news\_etl\_pipeline/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ news\_etl\_dag.py         # Main DAG definition
â”‚
â”œâ”€â”€ extract.py                  # Extract data from NewsAPI
â”œâ”€â”€ transform.py                # Clean and normalize article data
â”œâ”€â”€ load.py                     # Load data into PostgreSQL
â”‚
â”œâ”€â”€ docker-compose.yml          # Runs Airflow + PostgreSQL + Scheduler
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # API keys and DB credentials
â””â”€â”€ README.md                   # You're here
